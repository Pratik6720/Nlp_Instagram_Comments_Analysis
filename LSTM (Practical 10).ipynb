{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNRk61aCL20L"
      },
      "source": [
        "## Practical 10 Text processing with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i42UiyuPIgh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUeiBP0X7Ls"
      },
      "source": [
        "train_df= pd.read_csv('taska.txt',sep='\\t',header=None,names=['id','text','class'])\n",
        "train_df['text'] = train_df['text'].fillna(\"something\").values\n",
        "train_df['class'] = np.where(train_df['class']=='OFF', 1, 0)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djdhGISibZlv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "edb0a498-42f6-4cd6-d5f4-57859b63939c"
      },
      "source": [
        "t1=pd.read_csv('testset-levela.tsv',sep='\\t')\n",
        "t1.head()\n",
        "t2=pd.read_csv('labels-levela.csv',sep=',',header=None,names=['id','class'])\n",
        "t2.head()\n",
        "test_df=pd.merge(t1,t2,how='inner',on=['id'])\n",
        "test_df['class'] = np.where(test_df['class']=='OFF', 1, 0)\n",
        "\n",
        "test_df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15923</td>\n",
              "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27014</td>\n",
              "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30530</td>\n",
              "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13876</td>\n",
              "      <td>#Watching #Boomer getting the news that she is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60133</td>\n",
              "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  class\n",
              "0  15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...      1\n",
              "1  27014  #ConstitutionDay is revered by Conservatives, ...      0\n",
              "2  30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...      0\n",
              "3  13876  #Watching #Boomer getting the news that she is...      0\n",
              "4  60133  #NoPasaran: Unity demo to oppose the far-right...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g05d4BJNdH93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb795a02-de1f-4bc5-d2c9-271b242701f0"
      },
      "source": [
        "train_df['class'].value_counts()\n",
        "#test_df['class'].value_counts()/\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8840\n",
              "1    4400\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnFqLghbc4Z"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# create training and testing vars\n",
        "train, valid= train_test_split(train_df, test_size=0.2, random_state=1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8DzZ44Ud-Ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272b8afc-0217-419e-93e2-22f01e8ce3a5"
      },
      "source": [
        "print(train.groupby('class').count()) \n",
        "print(valid.groupby('class').count())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         id  text\n",
            "class            \n",
            "0      7081  7081\n",
            "1      3511  3511\n",
            "         id  text\n",
            "class            \n",
            "0      1759  1759\n",
            "1       889   889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuO1LB2LyEKo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFgAOBP9yE2U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae435a5-b7b7-4caa-99ba-04472ce085fc"
      },
      "source": [
        "test_df.head()\n",
        "test_df.info()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 860 entries, 0 to 859\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      860 non-null    int64 \n",
            " 1   tweet   860 non-null    object\n",
            " 2   class   860 non-null    int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 26.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2vP0tXxeCtz"
      },
      "source": [
        "X_train = train['text']\n",
        "X_valid = valid['text']\n",
        "y_train=train['class']\n",
        "y_valid=valid['class']\n",
        "X_test = test_df['tweet'].fillna(\"something\").values\n",
        "y_test=test_df['class']\n",
        "y_test=test_df['class']"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTCVDyIuqqN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5668d885-32a3-4349-c7ee-a0726f56ce35"
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-22 13:41:47--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‚Äòcrawl-300d-2M-subword.zip.1‚Äô\n",
            "\n",
            "ip.1                  2%[                    ] 154.52M  23.5MB/s    eta 4m 12s ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boPcx0F6rKpy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0345f916-26cf-45c0-b924-90a40d17c310"
      },
      "source": [
        "#!unzip glove*.zip\n",
        "!unzip crawl-300d-2M-subword.zip\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  crawl-300d-2M-subword.zip\n",
            "replace crawl-300d-2M-subword.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace crawl-300d-2M-subword.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wcsNO61ML4x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzYrIxpqvXx9"
      },
      "source": [
        "embed_size = 300"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFpSLZDuqTz"
      },
      "source": [
        "#embedding_path='glove.6B.300d.txt'\n",
        "embedding_path='crawl-300d-2M-subword.vec'\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(embedding_path,encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.rstrip().rsplit(' ')\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdsiT8VLg9Dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4711760f-3c27-41d9-b8ca-3394cab3d137"
      },
      "source": [
        "len(embeddings_index)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-wx0CJpm2Y8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d2f458-786e-4630-8aa3-66e1dad685cd"
      },
      "source": [
        "embeddings_index['dhrumin']"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-4.000e-02, -3.250e-02,  6.260e-02, -7.100e-03,  6.350e-02,\n",
              "       -9.060e-02,  2.400e-02, -8.090e-02,  5.300e-03,  6.200e-03,\n",
              "        5.100e-03,  3.970e-02, -4.530e-02,  5.900e-03,  2.790e-02,\n",
              "        4.930e-02,  4.490e-02,  2.460e-02,  2.610e-02,  1.600e-02,\n",
              "       -2.700e-03,  3.110e-02,  7.360e-02, -1.580e-02, -1.080e-02,\n",
              "        8.290e-02, -1.020e-01,  3.230e-02, -1.820e-02,  3.900e-03,\n",
              "       -5.180e-02,  3.330e-02,  3.280e-02, -1.227e-01,  7.830e-02,\n",
              "       -4.790e-02,  8.980e-02,  7.390e-02, -2.590e-02, -1.560e-02,\n",
              "       -4.240e-02, -5.280e-02,  9.600e-03, -7.740e-02,  4.360e-02,\n",
              "        3.330e-02, -2.270e-02, -8.300e-02, -9.330e-02, -3.890e-02,\n",
              "       -5.680e-02,  7.170e-02, -3.900e-03,  1.998e-01, -4.220e-02,\n",
              "       -3.690e-02,  8.100e-03, -8.490e-02, -1.230e-02, -1.530e-02,\n",
              "       -4.000e-03, -9.630e-02, -7.030e-02, -6.710e-02, -4.200e-03,\n",
              "        4.900e-03,  7.300e-03, -9.750e-02, -1.700e-03, -1.054e-01,\n",
              "        1.799e-01, -5.150e-02, -3.970e-02, -1.420e-02, -7.620e-02,\n",
              "        7.230e-02,  1.260e-02,  5.900e-02,  1.065e-01,  2.640e-02,\n",
              "        1.600e-02,  9.120e-02, -8.760e-02, -1.000e-02, -1.710e-02,\n",
              "        7.400e-03,  3.710e-02,  6.530e-02, -1.160e-02, -3.250e-02,\n",
              "       -4.480e-02, -2.420e-02, -1.670e-02,  1.970e-02, -7.420e-02,\n",
              "       -9.020e-02, -4.580e-02,  3.100e-03, -3.030e-02,  6.330e-02,\n",
              "       -1.019e-01,  5.530e-02, -9.340e-02,  1.256e-01, -8.110e-02,\n",
              "        3.400e-03, -4.860e-02,  1.168e-01, -1.267e-01,  4.800e-03,\n",
              "        6.080e-02,  5.900e-02, -2.090e-02,  3.730e-02, -7.130e-02,\n",
              "       -5.350e-02, -1.700e-02,  4.830e-02, -2.000e-02, -9.670e-02,\n",
              "       -5.410e-02,  4.180e-02,  6.900e-03, -1.660e-02,  6.740e-02,\n",
              "       -2.600e-02, -5.050e-02, -6.410e-02, -5.330e-02, -1.347e-01,\n",
              "        5.700e-02,  3.990e-02,  1.210e-02,  7.640e-02, -1.010e-02,\n",
              "        1.194e-01,  7.460e-02, -1.460e-02,  4.960e-02,  5.690e-02,\n",
              "        3.240e-02,  7.450e-02,  5.150e-02, -9.020e-02,  1.770e-02,\n",
              "        4.870e-02,  1.820e-02,  1.132e-01,  7.740e-02,  6.230e-02,\n",
              "        6.530e-02,  1.564e-01, -2.100e-02, -4.150e-02,  7.900e-03,\n",
              "        9.720e-02, -3.950e-02,  2.490e-02, -1.660e-02,  2.500e-02,\n",
              "       -2.420e-02,  2.070e-02, -3.080e-02, -4.040e-02,  4.900e-03,\n",
              "        7.210e-02, -4.580e-02,  5.900e-03,  9.540e-02, -4.480e-02,\n",
              "        9.410e-02,  3.100e-03,  4.580e-02, -3.510e-02, -5.460e-02,\n",
              "        7.000e-03,  1.200e-01,  2.290e-02,  1.059e-01, -6.290e-02,\n",
              "       -7.430e-02,  1.109e-01,  4.900e-02,  2.950e-02, -2.950e-02,\n",
              "       -2.630e-02, -1.029e-01, -2.030e-02,  2.970e-02, -2.700e-03,\n",
              "       -1.226e-01, -7.000e-04, -1.460e-02,  2.050e-02, -6.680e-02,\n",
              "       -1.080e-02,  7.470e-02, -1.087e-01, -2.000e-04, -1.520e-02,\n",
              "       -5.980e-02, -3.570e-02, -1.520e-02,  2.920e-02, -2.300e-03,\n",
              "       -5.990e-02,  5.440e-02,  1.069e-01, -7.000e-03, -6.870e-02,\n",
              "       -1.929e-01, -7.170e-02, -8.280e-02,  5.760e-02,  1.730e-02,\n",
              "        4.200e-02,  4.220e-02, -4.930e-02, -7.760e-02, -7.800e-03,\n",
              "       -1.200e-03,  3.400e-03,  1.670e-02,  1.738e-01,  1.933e-01,\n",
              "       -2.560e-02, -3.930e-02,  2.830e-02, -4.760e-02,  1.440e-02,\n",
              "       -6.000e-04, -3.410e-02,  8.700e-02, -1.298e-01,  1.760e-02,\n",
              "        2.370e-02, -3.730e-02, -4.380e-02,  3.820e-02, -1.120e-02,\n",
              "       -4.590e-02,  8.290e-02,  5.660e-02, -2.426e-01, -1.097e-01,\n",
              "        1.194e-01, -1.635e-01, -5.630e-02, -6.540e-02, -1.600e-02,\n",
              "        4.220e-02,  5.280e-02, -3.700e-02,  1.207e-01,  3.180e-02,\n",
              "        1.650e-02,  6.090e-02,  2.180e-02, -3.490e-02,  6.600e-03,\n",
              "        8.730e-02, -7.530e-02, -8.430e-02, -1.740e-02,  1.180e-02,\n",
              "        4.550e-02,  5.000e-03, -4.490e-02,  9.400e-03,  2.780e-02,\n",
              "        6.190e-02, -1.232e-01, -3.780e-02, -4.490e-02, -5.800e-02,\n",
              "        8.860e-02, -1.157e-01,  1.454e-01, -7.140e-02, -3.670e-02,\n",
              "       -1.527e-01,  6.580e-02, -4.800e-03, -6.770e-02, -8.640e-02,\n",
              "       -3.830e-02, -5.100e-02, -1.335e-01, -2.080e-02,  6.920e-02,\n",
              "        8.450e-02,  6.740e-02, -5.130e-02, -5.670e-02,  1.069e-01,\n",
              "        1.087e-01,  6.470e-02,  8.820e-02, -1.225e-01,  9.210e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rc4M__7u4gB"
      },
      "source": [
        "max_len = 30\n",
        "max_words=10000\n",
        "\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGovV58GhK55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b2e8f4-6091-46c0-fd0c-2b24c77d80df"
      },
      "source": [
        "X_train[1]\n",
        "sequences_matrix[2]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "          1,    1,    1,   82, 1411,    4,    7, 1090], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yGOA-inhdil",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8a88cbde-ef2b-4a86-e4ae-2f0177570811"
      },
      "source": [
        "X_train[77]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Don't forget @USER &amp; Democrat backed #Antifa\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogQXRQUQvGZP"
      },
      "source": [
        "word_index = tok.word_index\n",
        "#prepare embedding matrix\n",
        "num_words = min(max_words, len(word_index) + 1)\n",
        "import numpy as np\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMGXRQM6iDhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da4a2ec-3dfc-41ce-c472-8b509925d65b"
      },
      "source": [
        "len(word_index)\n",
        "word_index"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user': 1,\n",
              " 'the': 2,\n",
              " 'is': 3,\n",
              " 'to': 4,\n",
              " 'a': 5,\n",
              " 'and': 6,\n",
              " 'you': 7,\n",
              " 'of': 8,\n",
              " 'are': 9,\n",
              " 'i': 10,\n",
              " 'he': 11,\n",
              " 'that': 12,\n",
              " 'in': 13,\n",
              " 'for': 14,\n",
              " 'she': 15,\n",
              " 'url': 16,\n",
              " 'it': 17,\n",
              " 'this': 18,\n",
              " 'on': 19,\n",
              " 'not': 20,\n",
              " 'they': 21,\n",
              " 'with': 22,\n",
              " 'have': 23,\n",
              " 'be': 24,\n",
              " 'liberals': 25,\n",
              " 'gun': 26,\n",
              " 'so': 27,\n",
              " 'all': 28,\n",
              " 'control': 29,\n",
              " 'antifa': 30,\n",
              " 'your': 31,\n",
              " 'like': 32,\n",
              " 'what': 33,\n",
              " 'as': 34,\n",
              " 'but': 35,\n",
              " 'just': 36,\n",
              " 'maga': 37,\n",
              " 'her': 38,\n",
              " 'we': 39,\n",
              " 'about': 40,\n",
              " 'was': 41,\n",
              " 'conservatives': 42,\n",
              " 'if': 43,\n",
              " 'who': 44,\n",
              " 'will': 45,\n",
              " 'do': 46,\n",
              " 'people': 47,\n",
              " 'no': 48,\n",
              " 'my': 49,\n",
              " 'his': 50,\n",
              " 'by': 51,\n",
              " 'at': 52,\n",
              " 'from': 53,\n",
              " 'has': 54,\n",
              " 'or': 55,\n",
              " 'how': 56,\n",
              " 'an': 57,\n",
              " 'amp': 58,\n",
              " 'up': 59,\n",
              " 'their': 60,\n",
              " 'me': 61,\n",
              " 'out': 62,\n",
              " 'get': 63,\n",
              " 'one': 64,\n",
              " 'more': 65,\n",
              " 'know': 66,\n",
              " 'trump': 67,\n",
              " 'why': 68,\n",
              " 'can': 69,\n",
              " 'when': 70,\n",
              " 'because': 71,\n",
              " 'them': 72,\n",
              " 'think': 73,\n",
              " 'him': 74,\n",
              " 'now': 75,\n",
              " 'would': 76,\n",
              " \"don't\": 77,\n",
              " 'there': 78,\n",
              " 'should': 79,\n",
              " 'right': 80,\n",
              " 'our': 81,\n",
              " 'good': 82,\n",
              " \"it's\": 83,\n",
              " 'only': 84,\n",
              " 'us': 85,\n",
              " 'time': 86,\n",
              " 'want': 87,\n",
              " 'need': 88,\n",
              " 'never': 89,\n",
              " 'go': 90,\n",
              " 'see': 91,\n",
              " 'then': 92,\n",
              " 'been': 93,\n",
              " 'being': 94,\n",
              " 'than': 95,\n",
              " 'going': 96,\n",
              " 'don‚Äôt': 97,\n",
              " 'love': 98,\n",
              " 'shit': 99,\n",
              " 'even': 100,\n",
              " 'say': 101,\n",
              " 'these': 102,\n",
              " 'back': 103,\n",
              " 'really': 104,\n",
              " 'too': 105,\n",
              " 'some': 106,\n",
              " 'make': 107,\n",
              " 'any': 108,\n",
              " 'way': 109,\n",
              " 'did': 110,\n",
              " 'it‚Äôs': 111,\n",
              " 'were': 112,\n",
              " 'still': 113,\n",
              " 'much': 114,\n",
              " 'over': 115,\n",
              " 'democrats': 116,\n",
              " 'left': 117,\n",
              " 'vote': 118,\n",
              " 'other': 119,\n",
              " 'had': 120,\n",
              " 'better': 121,\n",
              " 'well': 122,\n",
              " 'take': 123,\n",
              " 'u': 124,\n",
              " 'does': 125,\n",
              " 'most': 126,\n",
              " 'also': 127,\n",
              " 'said': 128,\n",
              " \"i'm\": 129,\n",
              " 'president': 130,\n",
              " 'believe': 131,\n",
              " 'where': 132,\n",
              " 'party': 133,\n",
              " '2': 134,\n",
              " 'keep': 135,\n",
              " 'against': 136,\n",
              " 'man': 137,\n",
              " 'those': 138,\n",
              " 'many': 139,\n",
              " 'country': 140,\n",
              " 'great': 141,\n",
              " 'kavanaugh': 142,\n",
              " 'down': 143,\n",
              " 'here': 144,\n",
              " 'nothing': 145,\n",
              " 'look': 146,\n",
              " 'another': 147,\n",
              " 'very': 148,\n",
              " 'liberal': 149,\n",
              " 'same': 150,\n",
              " \"that's\": 151,\n",
              " 'years': 152,\n",
              " 'could': 153,\n",
              " 'lol': 154,\n",
              " 'into': 155,\n",
              " 'hope': 156,\n",
              " 'always': 157,\n",
              " 'stop': 158,\n",
              " 'please': 159,\n",
              " 'doing': 160,\n",
              " 'i‚Äôm': 161,\n",
              " 'thing': 162,\n",
              " 'sure': 163,\n",
              " 'am': 164,\n",
              " 'trying': 165,\n",
              " 'off': 166,\n",
              " 'again': 167,\n",
              " 'got': 168,\n",
              " 'support': 169,\n",
              " 'life': 170,\n",
              " 'every': 171,\n",
              " 'after': 172,\n",
              " 'hate': 173,\n",
              " 'ever': 174,\n",
              " 'money': 175,\n",
              " 'america': 176,\n",
              " 'thank': 177,\n",
              " 'work': 178,\n",
              " 'yes': 179,\n",
              " 'care': 180,\n",
              " 'such': 181,\n",
              " 'laws': 182,\n",
              " 'ass': 183,\n",
              " 'fuck': 184,\n",
              " 'god': 185,\n",
              " 'help': 186,\n",
              " 'getting': 187,\n",
              " 'its': 188,\n",
              " 'new': 189,\n",
              " 'women': 190,\n",
              " 'tell': 191,\n",
              " 'away': 192,\n",
              " 'wrong': 193,\n",
              " 'which': 194,\n",
              " \"can't\": 195,\n",
              " 'give': 196,\n",
              " 'big': 197,\n",
              " 'real': 198,\n",
              " '1': 199,\n",
              " 'woman': 200,\n",
              " 'everyone': 201,\n",
              " \"you're\": 202,\n",
              " 'first': 203,\n",
              " 'white': 204,\n",
              " 'day': 205,\n",
              " 'oh': 206,\n",
              " 'call': 207,\n",
              " 'saying': 208,\n",
              " 'come': 209,\n",
              " 'law': 210,\n",
              " 'best': 211,\n",
              " 'anything': 212,\n",
              " 'needs': 213,\n",
              " 'old': 214,\n",
              " 'everything': 215,\n",
              " 'maybe': 216,\n",
              " 'person': 217,\n",
              " 'let': 218,\n",
              " 'actually': 219,\n",
              " 'bad': 220,\n",
              " 'made': 221,\n",
              " 'guns': 222,\n",
              " 'someone': 223,\n",
              " 'anyone': 224,\n",
              " 'before': 225,\n",
              " 'fucking': 226,\n",
              " 'since': 227,\n",
              " 'show': 228,\n",
              " 'something': 229,\n",
              " 'world': 230,\n",
              " 'guy': 231,\n",
              " 'both': 232,\n",
              " 'things': 233,\n",
              " 'that‚Äôs': 234,\n",
              " 'government': 235,\n",
              " 'violence': 236,\n",
              " 'put': 237,\n",
              " \"doesn't\": 238,\n",
              " 'enough': 239,\n",
              " 'long': 240,\n",
              " 'he‚Äôs': 241,\n",
              " 'funny': 242,\n",
              " 'must': 243,\n",
              " 'own': 244,\n",
              " 'black': 245,\n",
              " 'yet': 246,\n",
              " 'year': 247,\n",
              " 'done': 248,\n",
              " 'news': 249,\n",
              " 'already': 250,\n",
              " 'mean': 251,\n",
              " 'fake': 252,\n",
              " 'obama': 253,\n",
              " 'use': 254,\n",
              " 'anti': 255,\n",
              " 'twitter': 256,\n",
              " 'try': 257,\n",
              " 'point': 258,\n",
              " 'while': 259,\n",
              " 'truth': 260,\n",
              " 'american': 261,\n",
              " 'next': 262,\n",
              " 'far': 263,\n",
              " 'dems': 264,\n",
              " 'part': 265,\n",
              " 'true': 266,\n",
              " 'state': 267,\n",
              " 'follow': 268,\n",
              " 'last': 269,\n",
              " 'stupid': 270,\n",
              " 'can‚Äôt': 271,\n",
              " 'lying': 272,\n",
              " 'may': 273,\n",
              " 'thought': 274,\n",
              " 'talking': 275,\n",
              " 'republicans': 276,\n",
              " 'talk': 277,\n",
              " 'start': 278,\n",
              " 'doesn‚Äôt': 279,\n",
              " 'says': 280,\n",
              " 'job': 281,\n",
              " 'hard': 282,\n",
              " 'racist': 283,\n",
              " 'free': 284,\n",
              " 'üòÇ': 285,\n",
              " 'looking': 286,\n",
              " 'little': 287,\n",
              " 'media': 288,\n",
              " 'conservative': 289,\n",
              " 'making': 290,\n",
              " 'rights': 291,\n",
              " 'makes': 292,\n",
              " 'read': 293,\n",
              " 'feel': 294,\n",
              " 'used': 295,\n",
              " \"he's\": 296,\n",
              " 'lot': 297,\n",
              " 'through': 298,\n",
              " 'power': 299,\n",
              " \"didn't\": 300,\n",
              " 'remember': 301,\n",
              " 'nra': 302,\n",
              " 'sorry': 303,\n",
              " 'americans': 304,\n",
              " 'gop': 305,\n",
              " 'thanks': 306,\n",
              " 'looks': 307,\n",
              " '4': 308,\n",
              " 'beautiful': 309,\n",
              " 'yeah': 310,\n",
              " 'high': 311,\n",
              " 'watch': 312,\n",
              " 'today': 313,\n",
              " 'wants': 314,\n",
              " 'stand': 315,\n",
              " 'sense': 316,\n",
              " 'reason': 317,\n",
              " 'having': 318,\n",
              " '3': 319,\n",
              " 'called': 320,\n",
              " 'understand': 321,\n",
              " 'school': 322,\n",
              " 'name': 323,\n",
              " 'ago': 324,\n",
              " 'game': 325,\n",
              " 'change': 326,\n",
              " 'under': 327,\n",
              " 'until': 328,\n",
              " 'ok': 329,\n",
              " 'didn‚Äôt': 330,\n",
              " 'around': 331,\n",
              " 'probably': 332,\n",
              " 'political': 333,\n",
              " 'pretty': 334,\n",
              " 'coming': 335,\n",
              " 'fact': 336,\n",
              " 'home': 337,\n",
              " 'bitch': 338,\n",
              " 'lies': 339,\n",
              " \"isn't\": 340,\n",
              " 'lost': 341,\n",
              " 'amazing': 342,\n",
              " 'democrat': 343,\n",
              " 'two': 344,\n",
              " 'knows': 345,\n",
              " 'working': 346,\n",
              " 'kind': 347,\n",
              " 'end': 348,\n",
              " 'police': 349,\n",
              " 'find': 350,\n",
              " 'problem': 351,\n",
              " 'walkaway': 352,\n",
              " 'happy': 353,\n",
              " 'cause': 354,\n",
              " \"they're\": 355,\n",
              " 'exactly': 356,\n",
              " 'means': 357,\n",
              " 'tweet': 358,\n",
              " 'dont': 359,\n",
              " 'using': 360,\n",
              " 'guess': 361,\n",
              " 'without': 362,\n",
              " 'girl': 363,\n",
              " 'matter': 364,\n",
              " 'qanon': 365,\n",
              " 'gets': 366,\n",
              " 'though': 367,\n",
              " 'you‚Äôre': 368,\n",
              " 'supporters': 369,\n",
              " 'win': 370,\n",
              " 'seen': 371,\n",
              " 'family': 372,\n",
              " 'chicago': 373,\n",
              " 'wwg1wga': 374,\n",
              " 'group': 375,\n",
              " 'crazy': 376,\n",
              " 'lie': 377,\n",
              " 'üá∫üá∏': 378,\n",
              " 'judge': 379,\n",
              " 'im': 380,\n",
              " 'seems': 381,\n",
              " 'hell': 382,\n",
              " 'republican': 383,\n",
              " \"she's\": 384,\n",
              " 'side': 385,\n",
              " 'whole': 386,\n",
              " 'public': 387,\n",
              " 'kag': 388,\n",
              " 'agree': 389,\n",
              " 'ask': 390,\n",
              " 'case': 391,\n",
              " 'word': 392,\n",
              " 'face': 393,\n",
              " 'place': 394,\n",
              " 'house': 395,\n",
              " 'play': 396,\n",
              " 'violent': 397,\n",
              " 'war': 398,\n",
              " 'election': 399,\n",
              " 'issue': 400,\n",
              " 'comes': 401,\n",
              " 'either': 402,\n",
              " 'sick': 403,\n",
              " 'fight': 404,\n",
              " 'men': 405,\n",
              " 'wow': 406,\n",
              " 'live': 407,\n",
              " 'else': 408,\n",
              " 'usa': 409,\n",
              " 'mind': 410,\n",
              " 'question': 411,\n",
              " 'ones': 412,\n",
              " 'absolutely': 413,\n",
              " '5': 414,\n",
              " 'idea': 415,\n",
              " 'pay': 416,\n",
              " 'history': 417,\n",
              " 'children': 418,\n",
              " 'politics': 419,\n",
              " 'ford': 420,\n",
              " 'kids': 421,\n",
              " 'calling': 422,\n",
              " 'few': 423,\n",
              " 'disgusting': 424,\n",
              " 'might': 425,\n",
              " 'took': 426,\n",
              " 'attack': 427,\n",
              " 'once': 428,\n",
              " 'instead': 429,\n",
              " 'wonder': 430,\n",
              " 'sad': 431,\n",
              " 'patriots': 432,\n",
              " 'common': 433,\n",
              " 'taking': 434,\n",
              " 'assault': 435,\n",
              " 'citizens': 436,\n",
              " 'hear': 437,\n",
              " 'court': 438,\n",
              " 'proud': 439,\n",
              " 'she‚Äôs': 440,\n",
              " 'liar': 441,\n",
              " 'himself': 442,\n",
              " 'shot': 443,\n",
              " 'yourself': 444,\n",
              " 'dead': 445,\n",
              " 'child': 446,\n",
              " 'wait': 447,\n",
              " 'less': 448,\n",
              " 'glad': 449,\n",
              " 'leave': 450,\n",
              " 'gonna': 451,\n",
              " 'story': 452,\n",
              " 'facts': 453,\n",
              " 'words': 454,\n",
              " 'guys': 455,\n",
              " 'wanted': 456,\n",
              " 'isn‚Äôt': 457,\n",
              " 'lives': 458,\n",
              " 'behind': 459,\n",
              " 'death': 460,\n",
              " 'damn': 461,\n",
              " 'crime': 462,\n",
              " 'playing': 463,\n",
              " 'justice': 464,\n",
              " 'w': 465,\n",
              " 'course': 466,\n",
              " 'guilty': 467,\n",
              " 'others': 468,\n",
              " 'different': 469,\n",
              " 'themselves': 470,\n",
              " 'bill': 471,\n",
              " 'head': 472,\n",
              " 'ur': 473,\n",
              " 'become': 474,\n",
              " 'human': 475,\n",
              " 'team': 476,\n",
              " 'open': 477,\n",
              " 'thinks': 478,\n",
              " 'heard': 479,\n",
              " 'via': 480,\n",
              " 'run': 481,\n",
              " 'social': 482,\n",
              " 'list': 483,\n",
              " 'times': 484,\n",
              " 'sexual': 485,\n",
              " 'r': 486,\n",
              " '6': 487,\n",
              " 'paid': 488,\n",
              " 'lmao': 489,\n",
              " 'running': 490,\n",
              " 'happen': 491,\n",
              " 'full': 492,\n",
              " 'blame': 493,\n",
              " 'brexit': 494,\n",
              " 'soros': 495,\n",
              " 'red': 496,\n",
              " 'least': 497,\n",
              " 'stay': 498,\n",
              " 'tcot': 499,\n",
              " 'shooting': 500,\n",
              " 'shame': 501,\n",
              " 'thinking': 502,\n",
              " 'awesome': 503,\n",
              " 'nice': 504,\n",
              " 'hillary': 505,\n",
              " 'told': 506,\n",
              " '‚Äù': 507,\n",
              " '10': 508,\n",
              " 'deal': 509,\n",
              " 'criminals': 510,\n",
              " 'lose': 511,\n",
              " 'hey': 512,\n",
              " 'fbi': 513,\n",
              " 'rest': 514,\n",
              " 'evil': 515,\n",
              " 'watching': 516,\n",
              " 'clinton': 517,\n",
              " 'b': 518,\n",
              " 's': 519,\n",
              " 'bullshit': 520,\n",
              " 'leftist': 521,\n",
              " 'line': 522,\n",
              " 'canada': 523,\n",
              " 'listen': 524,\n",
              " 'evidence': 525,\n",
              " 'young': 526,\n",
              " 'following': 527,\n",
              " 'tax': 528,\n",
              " 'cute': 529,\n",
              " 'answer': 530,\n",
              " 'shut': 531,\n",
              " 'together': 532,\n",
              " 'hurt': 533,\n",
              " 'voted': 534,\n",
              " 'safe': 535,\n",
              " 'victim': 536,\n",
              " 'false': 537,\n",
              " 'telling': 538,\n",
              " 'constitution': 539,\n",
              " 'book': 540,\n",
              " 'hit': 541,\n",
              " 'works': 542,\n",
              " 'bring': 543,\n",
              " \"won't\": 544,\n",
              " 'corrupt': 545,\n",
              " 'fine': 546,\n",
              " 'agenda': 547,\n",
              " 'days': 548,\n",
              " 'congress': 549,\n",
              " 'correct': 550,\n",
              " 'speak': 551,\n",
              " 'n': 552,\n",
              " 'thats': 553,\n",
              " 'goes': 554,\n",
              " 'friend': 555,\n",
              " 'fascist': 556,\n",
              " 'seriously': 557,\n",
              " 'between': 558,\n",
              " 'sex': 559,\n",
              " 'literally': 560,\n",
              " 'democratic': 561,\n",
              " 'proven': 562,\n",
              " 'worst': 563,\n",
              " 'soon': 564,\n",
              " 'nfl': 565,\n",
              " 'saw': 566,\n",
              " 'went': 567,\n",
              " 'innocent': 568,\n",
              " 'cannot': 569,\n",
              " 'hold': 570,\n",
              " 'cnn': 571,\n",
              " 'knew': 572,\n",
              " 'destroy': 573,\n",
              " 'truly': 574,\n",
              " 'week': 575,\n",
              " 'deep': 576,\n",
              " 'bet': 577,\n",
              " 'i‚Äôve': 578,\n",
              " 'illegal': 579,\n",
              " 'california': 580,\n",
              " 'million': 581,\n",
              " '100': 582,\n",
              " 'self': 583,\n",
              " 'sucks': 584,\n",
              " 'forget': 585,\n",
              " 'found': 586,\n",
              " 'poor': 587,\n",
              " 'baby': 588,\n",
              " 'nazis': 589,\n",
              " 'idiot': 590,\n",
              " 'supporting': 591,\n",
              " 'forward': 592,\n",
              " 'realize': 593,\n",
              " 'act': 594,\n",
              " 'dude': 595,\n",
              " 'office': 596,\n",
              " 'tried': 597,\n",
              " 'asking': 598,\n",
              " 'low': 599,\n",
              " \"aren't\": 600,\n",
              " 'class': 601,\n",
              " 'imagine': 602,\n",
              " 'almost': 603,\n",
              " 'bs': 604,\n",
              " 'hand': 605,\n",
              " 'happened': 606,\n",
              " 'ppl': 607,\n",
              " 'crap': 608,\n",
              " 'clear': 609,\n",
              " 'sounds': 610,\n",
              " 'proof': 611,\n",
              " 'friends': 612,\n",
              " 'elected': 613,\n",
              " 'gone': 614,\n",
              " 'kill': 615,\n",
              " 'society': 616,\n",
              " 'labour': 617,\n",
              " 'past': 618,\n",
              " 'claim': 619,\n",
              " 'completely': 620,\n",
              " 'dumb': 621,\n",
              " 'move': 622,\n",
              " 'gt': 623,\n",
              " 'terrorist': 624,\n",
              " 'joke': 625,\n",
              " 'each': 626,\n",
              " 'wing': 627,\n",
              " 'started': 628,\n",
              " 'boy': 629,\n",
              " 'except': 630,\n",
              " 'able': 631,\n",
              " 'business': 632,\n",
              " 'beat': 633,\n",
              " 'report': 634,\n",
              " 'metoo': 635,\n",
              " 'fighting': 636,\n",
              " '20': 637,\n",
              " 'fun': 638,\n",
              " 'attention': 639,\n",
              " 'voters': 640,\n",
              " 'omg': 641,\n",
              " 'clearly': 642,\n",
              " 'defend': 643,\n",
              " 'important': 644,\n",
              " '2a': 645,\n",
              " 'economy': 646,\n",
              " 'piece': 647,\n",
              " \"there's\": 648,\n",
              " 'mr': 649,\n",
              " 'holder': 650,\n",
              " 'longer': 651,\n",
              " 'disgrace': 652,\n",
              " 'health': 653,\n",
              " 'tweets': 654,\n",
              " 'uk': 655,\n",
              " 'top': 656,\n",
              " 'alone': 657,\n",
              " 'nazi': 658,\n",
              " 'unless': 659,\n",
              " 'criminal': 660,\n",
              " 'known': 661,\n",
              " 'character': 662,\n",
              " 'jail': 663,\n",
              " 'turn': 664,\n",
              " 'takes': 665,\n",
              " 'smart': 666,\n",
              " 'race': 667,\n",
              " 'video': 668,\n",
              " 'leader': 669,\n",
              " \"i'll\": 670,\n",
              " 'ya': 671,\n",
              " 'rather': 672,\n",
              " 'second': 673,\n",
              " 'prove': 674,\n",
              " 'obviously': 675,\n",
              " 'allow': 676,\n",
              " 'speech': 677,\n",
              " 'post': 678,\n",
              " 'blm': 679,\n",
              " 'voting': 680,\n",
              " 'states': 681,\n",
              " 'rules': 682,\n",
              " 'learn': 683,\n",
              " 'strict': 684,\n",
              " 'seem': 685,\n",
              " 'night': 686,\n",
              " 'texas': 687,\n",
              " 'shows': 688,\n",
              " 'tired': 689,\n",
              " \"wasn't\": 690,\n",
              " 'perfect': 691,\n",
              " 'gave': 692,\n",
              " 'account': 693,\n",
              " 'check': 694,\n",
              " 'mass': 695,\n",
              " 'policies': 696,\n",
              " 'close': 697,\n",
              " 'break': 698,\n",
              " 'opinion': 699,\n",
              " 'scared': 700,\n",
              " '2nd': 701,\n",
              " 'non': 702,\n",
              " 'cares': 703,\n",
              " 'donald': 704,\n",
              " 'potus': 705,\n",
              " 'likely': 706,\n",
              " 'total': 707,\n",
              " 'argument': 708,\n",
              " 'won‚Äôt': 709,\n",
              " 'nation': 710,\n",
              " 'majority': 711,\n",
              " 'giving': 712,\n",
              " 'half': 713,\n",
              " 'tories': 714,\n",
              " 'winning': 715,\n",
              " 'welcome': 716,\n",
              " 'horrible': 717,\n",
              " 'dangerous': 718,\n",
              " 'threats': 719,\n",
              " 'herself': 720,\n",
              " 'bless': 721,\n",
              " 'ignorant': 722,\n",
              " 'during': 723,\n",
              " 'plan': 724,\n",
              " 'accuser': 725,\n",
              " 'zero': 726,\n",
              " 'kkk': 727,\n",
              " 'quite': 728,\n",
              " 'murder': 729,\n",
              " 'mental': 730,\n",
              " 'rape': 731,\n",
              " 'rednationrising': 732,\n",
              " 'worse': 733,\n",
              " 'trudeau': 734,\n",
              " 'fast': 735,\n",
              " 'abuse': 736,\n",
              " 'buy': 737,\n",
              " 'entire': 738,\n",
              " 'whatever': 739,\n",
              " 'definitely': 740,\n",
              " 'future': 741,\n",
              " 'strong': 742,\n",
              " \"wouldn't\": 743,\n",
              " 'respect': 744,\n",
              " 'military': 745,\n",
              " 'issues': 746,\n",
              " '7': 747,\n",
              " \"what's\": 748,\n",
              " 'miss': 749,\n",
              " 'due': 750,\n",
              " \"i've\": 751,\n",
              " 'msm': 752,\n",
              " 'worth': 753,\n",
              " 'anymore': 754,\n",
              " 'father': 755,\n",
              " 'term': 756,\n",
              " 'movement': 757,\n",
              " 'killed': 758,\n",
              " 'trust': 759,\n",
              " 'biggest': 760,\n",
              " 'groups': 761,\n",
              " 'housing': 762,\n",
              " 'socialist': 763,\n",
              " 'trash': 764,\n",
              " 'chance': 765,\n",
              " 'push': 766,\n",
              " \"let's\": 767,\n",
              " 'serena': 768,\n",
              " 'protect': 769,\n",
              " 'terrorists': 770,\n",
              " 'save': 771,\n",
              " 'fan': 772,\n",
              " 'lt': 773,\n",
              " 'deserve': 774,\n",
              " 'abortion': 775,\n",
              " 'join': 776,\n",
              " 'üôÑ': 777,\n",
              " 'let‚Äôs': 778,\n",
              " 'finally': 779,\n",
              " 'mouth': 780,\n",
              " 'hearing': 781,\n",
              " 'excuse': 782,\n",
              " 'actions': 783,\n",
              " 'fear': 784,\n",
              " '15': 785,\n",
              " 'killing': 786,\n",
              " 'dem': 787,\n",
              " 'along': 788,\n",
              " 'set': 789,\n",
              " 'bc': 790,\n",
              " 'article': 791,\n",
              " 'apparently': 792,\n",
              " 'cops': 793,\n",
              " 'followed': 794,\n",
              " 'parents': 795,\n",
              " 'alt': 796,\n",
              " 'confirmkavanaugh': 797,\n",
              " 'came': 798,\n",
              " 'living': 799,\n",
              " 'sides': 800,\n",
              " '30': 801,\n",
              " 'feinstein': 802,\n",
              " 'single': 803,\n",
              " 'wall': 804,\n",
              " 'pro': 805,\n",
              " 'senate': 806,\n",
              " 'wish': 807,\n",
              " 'protest': 808,\n",
              " 'college': 809,\n",
              " 'member': 810,\n",
              " 'send': 811,\n",
              " 'losing': 812,\n",
              " 'responsible': 813,\n",
              " 'stuff': 814,\n",
              " 'process': 815,\n",
              " 'dr': 816,\n",
              " 'numbers': 817,\n",
              " 'bit': 818,\n",
              " 'example': 819,\n",
              " 'view': 820,\n",
              " 'crying': 821,\n",
              " 'order': 822,\n",
              " 'google': 823,\n",
              " 'seeing': 824,\n",
              " 'continue': 825,\n",
              " 'taken': 826,\n",
              " 'supposed': 827,\n",
              " 'totally': 828,\n",
              " 'moment': 829,\n",
              " 'type': 830,\n",
              " 'heart': 831,\n",
              " 'members': 832,\n",
              " 'puerto': 833,\n",
              " 'fool': 834,\n",
              " 'dog': 835,\n",
              " 'joe': 836,\n",
              " 'eric': 837,\n",
              " 'allowed': 838,\n",
              " 'lady': 839,\n",
              " 'blue': 840,\n",
              " 'position': 841,\n",
              " 'freedom': 842,\n",
              " 'system': 843,\n",
              " 'player': 844,\n",
              " 'sensible': 845,\n",
              " 'given': 846,\n",
              " 'calls': 847,\n",
              " 'names': 848,\n",
              " 'career': 849,\n",
              " 'block': 850,\n",
              " 'form': 851,\n",
              " 'libs': 852,\n",
              " 'senator': 853,\n",
              " 'based': 854,\n",
              " 'campaign': 855,\n",
              " 'd': 856,\n",
              " 'democracy': 857,\n",
              " 'fat': 858,\n",
              " 'china': 859,\n",
              " 'holy': 860,\n",
              " 'amendment': 861,\n",
              " 'investigation': 862,\n",
              " 'tv': 863,\n",
              " 'hurricane': 864,\n",
              " 'culture': 865,\n",
              " 'supreme': 866,\n",
              " 'record': 867,\n",
              " 'football': 868,\n",
              " 'eat': 869,\n",
              " 't': 870,\n",
              " 'throw': 871,\n",
              " 'c': 872,\n",
              " 'ruin': 873,\n",
              " 'wife': 874,\n",
              " 'nigga': 875,\n",
              " 'carry': 876,\n",
              " 'nobody': 877,\n",
              " '2020': 878,\n",
              " 'pick': 879,\n",
              " 'they‚Äôre': 880,\n",
              " 'jobs': 881,\n",
              " 'feeling': 882,\n",
              " 'statement': 883,\n",
              " 'pope': 884,\n",
              " 'trumps': 885,\n",
              " 'neither': 886,\n",
              " 'expect': 887,\n",
              " 'aren‚Äôt': 888,\n",
              " 'shootings': 889,\n",
              " 'myself': 890,\n",
              " 'politicians': 891,\n",
              " 'legal': 892,\n",
              " 'anyway': 893,\n",
              " 'students': 894,\n",
              " 'lower': 895,\n",
              " 'boys': 896,\n",
              " 'pass': 897,\n",
              " 'asked': 898,\n",
              " 'target': 899,\n",
              " 'response': 900,\n",
              " 'wanna': 901,\n",
              " 'november': 902,\n",
              " 'perhaps': 903,\n",
              " 'millions': 904,\n",
              " 'simply': 905,\n",
              " 'female': 906,\n",
              " 'sweet': 907,\n",
              " 'doubt': 908,\n",
              " 'weird': 909,\n",
              " 'general': 910,\n",
              " 'showing': 911,\n",
              " 'hot': 912,\n",
              " 'ready': 913,\n",
              " 'safety': 914,\n",
              " 'serious': 915,\n",
              " 'suck': 916,\n",
              " 'drunk': 917,\n",
              " 'hopefully': 918,\n",
              " 'cool': 919,\n",
              " 'die': 920,\n",
              " 'actual': 921,\n",
              " 'leftists': 922,\n",
              " 'consider': 923,\n",
              " 'rule': 924,\n",
              " 'countries': 925,\n",
              " 'games': 926,\n",
              " 'vs': 927,\n",
              " 'fall': 928,\n",
              " 'none': 929,\n",
              " 'desperate': 930,\n",
              " 'level': 931,\n",
              " 'busy': 932,\n",
              " 'hands': 933,\n",
              " 'debate': 934,\n",
              " 'sound': 935,\n",
              " 'service': 936,\n",
              " 'including': 937,\n",
              " 'fault': 938,\n",
              " 'f': 939,\n",
              " 'behavior': 940,\n",
              " 'crimes': 941,\n",
              " 'armed': 942,\n",
              " 'cant': 943,\n",
              " 'questions': 944,\n",
              " 'fire': 945,\n",
              " 'weapons': 946,\n",
              " 'folks': 947,\n",
              " 'brother': 948,\n",
              " 'died': 949,\n",
              " 'favorite': 950,\n",
              " 'fraud': 951,\n",
              " 'i‚Äôll': 952,\n",
              " 'loves': 953,\n",
              " 'walk': 954,\n",
              " 'trump2020': 955,\n",
              " 'step': 956,\n",
              " 'allegations': 957,\n",
              " 'dirty': 958,\n",
              " '9': 959,\n",
              " 'reading': 960,\n",
              " 'speaking': 961,\n",
              " 'fascism': 962,\n",
              " 'scotus': 963,\n",
              " 'experience': 964,\n",
              " 'fascists': 965,\n",
              " 'ignore': 966,\n",
              " 'rate': 967,\n",
              " 'e': 968,\n",
              " 'kid': 969,\n",
              " 'rich': 970,\n",
              " 'tho': 971,\n",
              " 'brown': 972,\n",
              " \"who's\": 973,\n",
              " 'choice': 974,\n",
              " 'somehow': 975,\n",
              " 'season': 976,\n",
              " 'number': 977,\n",
              " 'votes': 978,\n",
              " 'honestly': 979,\n",
              " 'church': 980,\n",
              " 'waiting': 981,\n",
              " 'loved': 982,\n",
              " 'flag': 983,\n",
              " 'surprised': 984,\n",
              " 'accused': 985,\n",
              " 'months': 986,\n",
              " 'body': 987,\n",
              " 'difference': 988,\n",
              " 'wonderful': 989,\n",
              " 'comment': 990,\n",
              " 'trade': 991,\n",
              " 'christian': 992,\n",
              " 'views': 993,\n",
              " 'brain': 994,\n",
              " 'o': 995,\n",
              " 'üòÇüòÇ': 996,\n",
              " 'civil': 997,\n",
              " 'clue': 998,\n",
              " 'super': 999,\n",
              " 'gay': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5KdmNHUvLzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c40267d-2c19-4695-dd42-a5ec3f4900f9"
      },
      "source": [
        "word_index = tok.word_index\n",
        "#prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FLwFxaLvPHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43c33a6-0a9c-4098-83c6-cc03490dff20"
      },
      "source": [
        "embedding_matrix[1]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0312    , -0.1725    ,  0.109     ,  0.0666    ,  0.1096    ,\n",
              "       -0.0567    ,  0.1462    ,  0.008     ,  0.0539    ,  0.0407    ,\n",
              "       -0.0155    , -0.0214    , -0.0045    ,  0.0686    ,  0.0539    ,\n",
              "       -0.0596    ,  0.0071    ,  0.0969    ,  0.0454    ,  0.13169999,\n",
              "       -0.0024    , -0.0184    , -0.0505    ,  0.0121    , -0.0061    ,\n",
              "        0.1119    , -0.1138    ,  0.0483    , -0.0561    ,  0.1045    ,\n",
              "       -0.0279    , -0.1285    , -0.0924    ,  0.0052    ,  0.0944    ,\n",
              "       -0.0528    , -0.0238    , -0.1247    ,  0.0891    , -0.0802    ,\n",
              "        0.0578    , -0.25529999,  0.0024    , -0.0758    , -0.0809    ,\n",
              "        0.1027    , -0.029     ,  0.0626    , -0.0688    , -0.0611    ,\n",
              "        0.0291    ,  0.0455    ,  0.13249999,  0.13869999, -0.0631    ,\n",
              "        0.0439    ,  0.0362    ,  0.036     , -0.0834    ,  0.0378    ,\n",
              "        0.0943    , -0.0451    , -0.1032    , -0.0144    , -0.0164    ,\n",
              "        0.0098    , -0.01      , -0.0774    ,  0.0886    , -0.0149    ,\n",
              "        0.0646    , -0.0242    , -0.028     ,  0.083     , -0.0546    ,\n",
              "        0.0377    , -0.0092    ,  0.028     , -0.0518    ,  0.0037    ,\n",
              "        0.0795    ,  0.0419    ,  0.13869999,  0.1088    , -0.0633    ,\n",
              "       -0.0795    ,  0.0104    , -0.0612    ,  0.0233    ,  0.0812    ,\n",
              "       -0.0162    , -0.0024    ,  0.0357    ,  0.0539    , -0.031     ,\n",
              "        0.2762    , -0.0193    ,  0.0139    , -0.0172    ,  0.0368    ,\n",
              "       -0.082     , -0.0364    ,  0.0923    , -0.0456    , -0.0186    ,\n",
              "        0.0382    ,  0.0319    , -0.1058    ,  0.0979    , -0.0555    ,\n",
              "        0.0983    , -0.0504    ,  0.0659    , -0.13169999, -0.1032    ,\n",
              "       -0.0543    ,  0.0412    ,  0.0468    ,  0.0135    , -0.2085    ,\n",
              "        0.0379    ,  0.0767    ,  0.0222    , -0.093     , -0.0284    ,\n",
              "       -0.0504    , -0.0261    ,  0.0189    ,  0.0841    , -0.0534    ,\n",
              "       -0.0748    , -0.006     ,  0.0103    ,  0.0222    , -0.0208    ,\n",
              "        0.0155    ,  0.0333    ,  0.0348    ,  0.0709    , -0.0621    ,\n",
              "       -0.1185    ,  0.0477    ,  0.024     , -0.015     , -0.0463    ,\n",
              "        0.0832    ,  0.0072    , -0.0299    ,  0.0365    ,  0.035     ,\n",
              "       -0.0268    , -0.0697    , -0.0177    , -0.0569    ,  0.0919    ,\n",
              "        0.0408    , -0.021     , -0.0553    ,  0.0755    ,  0.0046    ,\n",
              "        0.0565    ,  0.0774    , -0.0115    , -0.0186    , -0.0412    ,\n",
              "        0.0668    ,  0.0453    , -0.018     ,  0.1227    , -0.0551    ,\n",
              "        0.0554    , -0.0526    ,  0.0682    , -0.0137    ,  0.0718    ,\n",
              "        0.0462    ,  0.1855    , -0.0515    , -0.1003    , -0.027     ,\n",
              "       -0.0494    ,  0.0469    , -0.048     , -0.1569    , -0.0218    ,\n",
              "       -0.0285    ,  0.0649    ,  0.0656    ,  0.0102    ,  0.0493    ,\n",
              "        0.0311    ,  0.0088    , -0.0489    ,  0.0464    ,  0.0567    ,\n",
              "        0.012     ,  0.0215    ,  0.1144    ,  0.062     ,  0.0328    ,\n",
              "       -0.1829    , -0.0403    , -0.0406    , -0.0655    ,  0.0059    ,\n",
              "       -0.0927    , -0.0178    ,  0.0043    ,  0.0704    , -0.0287    ,\n",
              "       -0.2221    , -0.0134    ,  0.0602    ,  0.0554    , -0.0014    ,\n",
              "       -0.0098    ,  0.0567    ,  0.0257    , -0.0605    , -0.0291    ,\n",
              "        0.0245    ,  0.0469    ,  0.1081    , -0.0462    ,  0.0599    ,\n",
              "       -0.0528    ,  0.13339999,  0.1285    , -0.0705    , -0.0846    ,\n",
              "       -0.0858    ,  0.0332    , -0.0897    , -0.0677    ,  0.0241    ,\n",
              "       -0.1149    , -0.0548    , -0.0553    ,  0.0506    ,  0.002     ,\n",
              "       -0.0514    ,  0.0198    , -0.0186    ,  0.0677    ,  0.0609    ,\n",
              "        0.0529    , -0.0991    , -0.1223    ,  0.0702    ,  0.0918    ,\n",
              "       -0.0216    ,  0.0734    , -0.0861    ,  0.1005    ,  0.1201    ,\n",
              "        0.0713    , -0.0146    ,  0.035     ,  0.0242    ,  0.0161    ,\n",
              "       -0.0497    ,  0.13339999, -0.0572    , -0.0251    ,  0.0075    ,\n",
              "       -0.1374    , -0.009     , -0.0432    , -0.0397    ,  0.1017    ,\n",
              "        0.1026    , -0.0024    , -0.13600001, -0.0039    , -0.018     ,\n",
              "        0.0497    ,  0.0874    ,  0.0211    ,  0.0092    ,  0.0482    ,\n",
              "        0.003     , -0.0056    ,  0.0131    ,  0.0838    , -0.0003    ,\n",
              "        0.0541    ,  0.0009    , -0.0511    ,  0.0386    , -0.0212    ,\n",
              "       -0.0106    , -0.0081    , -0.16069999,  0.0542    ,  0.0523    ,\n",
              "        0.0139    ,  0.0302    ,  0.0179    , -0.0627    , -0.0434    ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-MjSlOQvkCW"
      },
      "source": [
        "def RNN():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(num_words,300,input_length=max_len,weights=[embedding_matrix])(inputs)\n",
        "    #layer = Embedding(num_words,300,input_length=max_len)(inputs)\n",
        "\n",
        "    #layer = Embedding(max_words,300,input_length=max_len)(inputs)\n",
        "\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyL7igWSwKJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2a30fb-7c87-46de-8df2-8dc975bb59e1"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model = RNN()\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 30)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 30, 300)           3000000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                93440     \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 256)               16640     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 257       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,110,337\n",
            "Trainable params: 3,110,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vaq-hSV5xFJk"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "file_path = \"lstm_model_glove300_.{epoch:02d}-{val_acc:.8f}.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = False, mode = \"min\")\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxZH6S0fxbkZ"
      },
      "source": [
        "valid_sequences = tok.texts_to_sequences(X_valid)\n",
        "valid_sequences_matrix = sequence.pad_sequences(valid_sequences,maxlen=max_len)\n",
        "\n",
        "\n",
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJO9fDzNjaDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7a371e-b38e-4ce4-8d79-2dc8b3aa611c"
      },
      "source": [
        "valid_sequences_matrix[1]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 289,  133,  254, 4384,    8,  959, 1565,   68,    9,    2,   42,\n",
              "         27,  939, 1132,   43,    7,  390,   61,   83, 6997,   34,   21,\n",
              "       1127,  547,   55,    9,   21,   36,   12, 1132], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUErJkCJxcaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc4cec2-f218-4f69-fab9-43938f480875"
      },
      "source": [
        "#model.fit(sequences_matrix,y_train, batch_size=128, epochs=5, validation_data=(valid_sequences_matrix, y_valid), callbacks = [check_point])\n",
        "\n",
        "model.fit(sequences_matrix,y_train, batch_size=128, epochs=2, validation_data=(valid_sequences_matrix, y_valid))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "83/83 [==============================] - 3s 38ms/step - loss: 0.5910 - accuracy: 0.6935 - val_loss: 0.5394 - val_accuracy: 0.7379\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 3s 33ms/step - loss: 0.4151 - accuracy: 0.8185 - val_loss: 0.5185 - val_accuracy: 0.7606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4505d8f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2whWlXhpyNiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a59429-2dcb-44b5-91b1-07d2cff1482a"
      },
      "source": [
        "Y_valid=y_valid\n",
        "from sklearn import metrics\n",
        "import keras\n",
        "y_pred_prob=model.predict(valid_sequences_matrix)\n",
        "#y_pred_class = model.\n",
        "y_pred_class = (y_pred_prob >= 0.5).astype(np.int)\n",
        "print(metrics.confusion_matrix(Y_valid, y_pred_class))\n",
        "print (metrics.precision_score(Y_valid, y_pred_class,average= 'weighted'))\n",
        "print(metrics.recall_score(Y_valid, y_pred_class,average= 'weighted'))\n",
        "print (metrics.f1_score(Y_valid, y_pred_class, average= 'weighted'))\n",
        "#print (metrics.f1_score(y_test, y_pred_class))\n",
        "print(metrics.classification_report(Y_valid, y_pred_class))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1458  301]\n",
            " [ 333  556]]\n",
            "0.7585764887497342\n",
            "0.7605740181268882\n",
            "0.7594590686180253\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82      1759\n",
            "           1       0.65      0.63      0.64       889\n",
            "\n",
            "    accuracy                           0.76      2648\n",
            "   macro avg       0.73      0.73      0.73      2648\n",
            "weighted avg       0.76      0.76      0.76      2648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTw_op-ezkPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53619e61-d97b-4a60-d9b5-4d0ef416705b"
      },
      "source": [
        "ty_pred_prob=model.predict(test_sequences_matrix)\n",
        "ty_pred_class = (ty_pred_prob >= 0.5).astype(np.int)\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, ty_pred_class))\n",
        "print (metrics.precision_score(y_test, ty_pred_class,average= 'weighted'))\n",
        "print(metrics.recall_score(y_test, ty_pred_class,average= 'weighted'))\n",
        "print (metrics.f1_score(y_test, ty_pred_class, average= 'weighted'))\n",
        "print (metrics.f1_score(y_test, ty_pred_class))\n",
        "print(metrics.accuracy_score(y_test,ty_pred_class))\n",
        "print(metrics.classification_report(y_test, ty_pred_class,target_names=['0','1']))\n",
        "test_df['pred_taska']=ty_pred_class\n",
        "#test_df.head()\n",
        "#test_df[test_df['pred_taska']==1].info()\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[526  94]\n",
            " [ 92 148]]\n",
            "0.7842780521817448\n",
            "0.7837209302325582\n",
            "0.7839949416161045\n",
            "0.6141078838174274\n",
            "0.7837209302325582\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       620\n",
            "           1       0.61      0.62      0.61       240\n",
            "\n",
            "    accuracy                           0.78       860\n",
            "   macro avg       0.73      0.73      0.73       860\n",
            "weighted avg       0.78      0.78      0.78       860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzFinzmYz1oD"
      },
      "source": [
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsnx_ExvB6p0"
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "import numpy\n",
        "numpy.random.seed(seed)\n",
        "model_cnn_02 = Sequential()\n",
        "e = Embedding(10000, 300, input_length=30,weights=[embedding_matrix])\n",
        "#e = Embedding(10000, 300, input_length=1000)\n",
        "\n",
        "model_cnn_02.add(e)\n",
        "model_cnn_02.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "model_cnn_02.add(GlobalMaxPooling1D())\n",
        "model_cnn_02.add(Dense(256, activation='relu'))\n",
        "model_cnn_02.add(Dense(1, activation='sigmoid'))\n",
        "#file_path = \"CNNbest_model.hdf5\"\n",
        "file_path = \"model-taska/CNNbest_model_en_fasttext300.{epoch:02d}-{val_acc:.8f}.hdf5\"\n",
        "\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
        "                              save_best_only = False, mode = \"min\")\n",
        "#ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "early_stop = EarlyStopping(monitor = \"val_loss\", min_delta=0.0001)\n",
        "model_cnn_02.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivesiHDxTq3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e443640b-60db-4686-bc31-1924b7156f62"
      },
      "source": [
        "model_cnn_02.fit(sequences_matrix,y_train, batch_size=128, epochs=2, validation_data=(valid_sequences_matrix, y_valid))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "83/83 [==============================] - 3s 32ms/step - loss: 0.5791 - accuracy: 0.7014 - val_loss: 0.5045 - val_accuracy: 0.7727\n",
            "Epoch 2/2\n",
            "83/83 [==============================] - 3s 31ms/step - loss: 0.4098 - accuracy: 0.8184 - val_loss: 0.4814 - val_accuracy: 0.7776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc450553208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyR2D9_cCJx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1325201-5d6c-46ee-e2d7-98246f03683d"
      },
      "source": [
        "from sklearn import metrics\n",
        "import keras\n",
        "model=model_cnn_02\n",
        "from sklearn import metrics\n",
        "import keras\n",
        "y_pred_prob=model.predict(valid_sequences_matrix)\n",
        "#y_pred_class = model.\n",
        "y_pred_class = (y_pred_prob >= 0.5).astype(np.int)\n",
        "print(metrics.confusion_matrix(Y_valid, y_pred_class))\n",
        "print (metrics.precision_score(Y_valid, y_pred_class,average= 'weighted'))\n",
        "print(metrics.recall_score(Y_valid, y_pred_class,average= 'weighted'))\n",
        "print (metrics.f1_score(Y_valid, y_pred_class, average= 'weighted'))\n",
        "#print (metrics.f1_score(y_test, y_pred_class))\n",
        "print(metrics.classification_report(Y_valid, y_pred_class))\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1567  192]\n",
            " [ 397  492]]\n",
            "0.7714858502226487\n",
            "0.7775679758308157\n",
            "0.7691977364132122\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.89      0.84      1759\n",
            "           1       0.72      0.55      0.63       889\n",
            "\n",
            "    accuracy                           0.78      2648\n",
            "   macro avg       0.76      0.72      0.73      2648\n",
            "weighted avg       0.77      0.78      0.77      2648\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCox4IGECRL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a72fb9-cd5d-47a3-ae31-b517cca63b60"
      },
      "source": [
        "model=model_cnn_02\n",
        "\n",
        "ty_pred_prob=model.predict(test_sequences_matrix)\n",
        "ty_pred_class = (ty_pred_prob >= 0.5).astype(np.int)\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, ty_pred_class))\n",
        "print (metrics.precision_score(y_test, ty_pred_class,average= 'weighted'))\n",
        "print(metrics.recall_score(y_test, ty_pred_class,average= 'weighted'))\n",
        "print (metrics.f1_score(y_test, ty_pred_class, average= 'weighted'))\n",
        "print (metrics.f1_score(y_test, ty_pred_class))\n",
        "print(metrics.accuracy_score(y_test,ty_pred_class))\n",
        "print(metrics.classification_report(y_test, ty_pred_class,target_names=['0','1']))\n",
        "test_df['pred_taska']=ty_pred_class\n",
        "#test_df.head()\n",
        "#test_df[test_df['pred_taska']==1].info()\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[572  48]\n",
            " [105 135]]\n",
            "0.8149879686063124\n",
            "0.8220930232558139\n",
            "0.8140156727529788\n",
            "0.6382978723404255\n",
            "0.8220930232558139\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.92      0.88       620\n",
            "           1       0.74      0.56      0.64       240\n",
            "\n",
            "    accuracy                           0.82       860\n",
            "   macro avg       0.79      0.74      0.76       860\n",
            "weighted avg       0.81      0.82      0.81       860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}