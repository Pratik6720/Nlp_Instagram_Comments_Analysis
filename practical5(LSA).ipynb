{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"practical5(LSA).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPDAerIm6HV1qXtaESKO4m4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"bvnmWTuNqF1X","executionInfo":{"status":"ok","timestamp":1601497267980,"user_tz":-330,"elapsed":52631,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"d13b8344-ba2b-44b9-c9b4-9ce69d90dc4f","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-YseObjNrPoB","executionInfo":{"status":"ok","timestamp":1601497290452,"user_tz":-330,"elapsed":2730,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"b0a9af80-3b0d-4ec2-9fc3-68bf5e897095","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import nltk\n","from sklearn.decomposition import TruncatedSVD\n","# If nltk stop word is not downloaded\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fbev8gJGrWEF","executionInfo":{"status":"ok","timestamp":1601497964882,"user_tz":-330,"elapsed":2387,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"f34b7ea0-2b91-4735-f45a-8c2ae0271e4e","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["import nltk,csv,numpy\n","nltk.download('punkt')\n","from nltk import sent_tokenize, word_tokenize, pos_tag\n","sentences=[]\n","reader = csv.reader(open('/content/drive/My Drive/instacomments.csv', 'rU'), delimiter= \",\",quotechar='|')\n","for line in reader:\n","    for field in line:\n","      sentences.append(field)\n","print(sentences)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: 'U' mode is deprecated\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"stream","text":["['user name', 'comments', 'madhura_makeupnhair', 'Canâ€™t wait for season 2!!!', '\"battatawada', 'Verified\"', 'Verified', 'abby_racer20', '@harshita1210 Miss Sanyukta.. wat abt Sadda Haq??', 'mirahul03', 'Kab aayegi à¤®à¤¿à¤°à¥à¤œà¤¼à¤¾à¤ªà¥à¤°', 'harshitasinha122', 'Yayyy ðŸ¤—ðŸ¤—ðŸ¤—', 'nikkhiillllll', '@divyenndu', 'samannawaj123', 'I am Big Fan of Mirzapur Series', '_beingasifkhan', 'Aur kitna wait karaoge yrr tum log abhi bhabhi or raja ka Scene dekh ke kaam chalana padta hai', 'harshitasinha122', 'ðŸ’ž', 'harshitasinha122', 'ðŸ‘ŒðŸ‘ŒðŸ‘Œ', 'harshitasinha122', 'ðŸ‘ŒðŸ‘ŒðŸ‘Œ', 'krishna_akkian', '25 September may be', 'siyasingh2801', 'ðŸ˜ðŸ˜', 'siyasingh2801', 'Wai', 'siyasingh2801', 'Waiting babyâ¤ï¸â¤ï¸', 'siyasingh2801', 'Plz be safe love....take care of yourselfâ¤ï¸â¤ï¸', 'sagarnitesh55', 'Oh my godðŸ˜ðŸ˜˜ you are so lovely !â¤ï¸', 'harsh_k_pvt', 'Most awatingâ¤ï¸ðŸ˜­', 'iamsudipamanna', 'â¤ï¸', 'dharmesh.dy', 'Excited ðŸ˜', 'krishnagopal.paul_official', '\"*Do you want to Any kind of portrait or painting wall painting ect. ?* click on the below *link*__ follow and D.M Or sms in there. _Your request will be accepted as soon as possible_ Please', ' support us and Shear more groups.. ðŸ˜ŠðŸ™ðŸ»?. . *Will get 20%to 30% OFF* \\U0001f929 Offer limited *HURRY UP* *Terms and condition applied* https://www.instagram.com/krishnagopal.paul_official/\"', 'babukha20', 'Oho Didi congratulationðŸ˜˜ðŸ˜˜ðŸ˜˜', 'babukha20', 'I am your big fan', 'babukha20', 'Please reply me', 'the_yashwant_pargi', '\"Kab aa raha hai ', ' date bataiye please\"', 'theasifsheikhsahab121', 'â¤ï¸â¤ï¸', 'harshitalovers', \"Can't wait ðŸ˜â¤ï¸â¤ï¸â¤ï¸\", 'harshitalovers', 'All the best @harshita1210 ðŸ˜â¤ï¸', 'harshitalovers', 'Excited ðŸ˜â¤ï¸â¤ï¸â¤ï¸', 'harshitalovers', 'â¤ï¸â¤ï¸â¤ï¸', 'harshitalovers', 'â¤ï¸â¤ï¸â¤ï¸', 'harshitalovers', 'â¤ï¸â¤ï¸', 'ambika_792', 'â¤ï¸â¤ï¸', 'harshita_gaur_memes', 'All the best @harshita1210 ðŸ˜â¤ï¸', 'harshita_gaur_memes', 'Dimpy â¤ï¸', 'harshita_gaur_memes', 'â¤ï¸â¤ï¸â¤ï¸', 'priyaroy1430', 'Awesome & very nice ðŸ‘ŒðŸ‘ŒðŸ‘Œ.... we are love u â¤â¤â¤', 'mukeshchoudhary930', 'Nice', 'insanelyharshitian', 'AwwwwwwðŸ˜˜ðŸ˜˜ðŸ˜˜', 'insanelyharshitian', 'Cant wait ðŸ˜', 'insanelyharshitian', 'All the bestðŸ’—ðŸ’—', 'yagneshsatpute', 'ðŸ”¥', 'shirinmansuri31', 'ðŸ˜ðŸ˜ðŸ˜', 'nilamparmar2324', 'Cutieee ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥', '_d_abhishek_', 'Common @harshita1210 ab bta bhi do mirzapur2 ki date ðŸ˜ŒðŸ¤—', 'himanshu_.saini', 'Give us the damn dates ðŸ˜', 'makeupbynidhikaushal', 'Thatâ€™s amazing @harshita1210 ðŸ‘ŒðŸ»ðŸ‘ŒðŸ»', 'a.nike.t_ac_18', 'Bas jaldi aa jao.. ðŸ˜ðŸ˜', 'shubhamnagre14', '@harshita1210 Eagarly waiting dimppyâ¤ï¸', 'mannat_manik_123', 'ðŸ”¥ðŸ”¥ðŸ”¥', 'manoj__more__', 'Finally .. Intejar khatam ..ðŸ˜‰ðŸ˜˜ðŸ˜˜ Love you harsha ðŸ˜˜ðŸ˜˜', 'manoj__more__', 'So excited ðŸ’—ðŸ’—', 'shawji_vivaan', 'ðŸ”¥', 'sumit_arya450', 'Are yaar kab ayega', 'sumit_arya450', 'Pls sacred games jaisa hag mat dena', 'mrshoaib0221', 'You â£ï¸â£ï¸', 'zoobearz', '@farooqak @tvora23 @sarfz #ujaarsurat', 'rahul.rajsingh.35', 'Jali release kro mzs2', 'sahilakascorpio', 'à¤¸à¥à¤µà¤¾à¤—à¤¤ à¤•à¤°à¥‡à¤‚à¤—à¥‡ à¤†à¤ªà¤•à¤¾', 'shiyaldarshan', 'Nice...', 'black_magic_specialist_guruji', '\"#à¤ªà¥‚à¤œà¤¾_ à¤µà¤¿à¤§à¤¿_à¤¦à¥à¤µà¤¾à¤°à¤¾_à¤•à¤°à¥à¤œà¤¾_à¤®à¥à¤•à¥à¤¤à¤¿_à¤®à¤¨à¤šà¤¾à¤¹à¤¾_à¤ªà¥à¤¯à¤¾à¤°_à¤µà¤°_à¤µà¤§à¥‚_à¤¸à¤­à¥€_à¤¸à¤®à¤¸à¥à¤¯à¤¾_à¤•à¤¾_à¤¸à¤®à¤¾à¤§à¤¾à¤¨à¥¤ à¤•à¥‰à¤² à¤•à¤°à¥‡-+91-89555-45742 â­ðŸŒŸâœ¨ðŸŒŸðŸŒ ðŸŒ ðŸ“¿ðŸ“¿ðŸ’«ðŸ’« #à¤¶à¤•à¥à¤¤à¤¿_à¤•à¤¾_à¤šà¤®à¤¤à¥à¤•à¤¾à¤°_à¤¦à¥‡à¤–à¥‡à¥¤ à¤…à¤ªà¤¨à¥€#à¤•à¤¿à¤¸à¥€ à¤­à¥€ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤•à¤¾ à¤¸à¤®à¤¾à¤§à¤¾à¤¨ à¤¤à¥à¤°à¤¨à¥à¤¤ #à¤˜à¤° à¤¬à¥ˆà¤ à¥‡_à¤¹à¤²_à¤•à¤°à¤µà¤¾à¤_à¤µà¥‹_à¤­à¥€_ðŸ’¯% à¤—à¤¾à¤°à¤‚à¤Ÿà¥€ à¤•à¥‡ à¤¸à¤¾à¤¥à¥¤ â˜Žï¸#à¤•à¥‰à¤²&#whatsapp-+91-89555-457-42 #à¤¹à¤®à¤¾à¤°à¥€_à¤¸à¥‡à¤µà¤¾à¤à¤‚:-speslist # vashikaran_mantra 2-LOVE PROBLEM SPECIALIST 3-BLACK MAGIC SPECIALIST 4-HUSBAND WIFE DISPUTE PROBLEM SOLUTION 5-LOVE VASHIKARAN SPECIALIST 6-VEDIC ASTROLOGY 7-JOB PROBLEM 8-COURT CASE 9- jaadu tona', ' foreign yatra', ' study', ' manglik dosh', 'kal sarp dosh etc.. #get_your_love_life #vashikaran specialist guruji pt.vk sharmaðŸ“¿ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤•à¥‡à¤¸à¥€ à¤­à¥€ à¤¹à¥‹ _à¤¤à¥à¤°à¤¨à¥à¤¤ à¤¸à¤®à¤¾à¤§à¤¾à¤¨... #à¤µà¤¶à¥€à¤•à¤°à¤£ à¤•à¤°à¤µà¤¾à¤¨à¤¾ à¤¯à¤¾ à¤¤à¥à¤¡à¤¼à¤µà¤¾à¤¨à¤¾ #à¤•à¤¿à¤¯à¤¾ à¤•à¤°à¤¾à¤¯à¤¾ #à¤¸à¥‹à¤¤à¤¨ à¤¸à¥‡ à¤›à¥à¤Ÿà¤•à¤¾à¤°à¤¾ #à¤¸à¤¨à¥à¤¤à¤¾à¤¨ à¤¨à¤¹à¥€à¤‚ à¤¹à¥‹à¤¨à¤¾ à¤¯à¤¾ à¤¹à¥‹à¤•à¤° à¤®à¤° à¤œà¤¾à¤¨à¤¾ #à¤ªà¤¤à¤¿- à¤ªà¤¤à¥à¤¨à¤¿ à¤•à¥‡ à¤à¤—à¤¡à¥‡ #à¤•à¤¾à¤² à¤¸à¤°à¥à¤ª à¤¦à¥‹à¤· #à¤®à¤¾à¤‚à¤—à¤²à¤¿à¤• à¤¦à¥‹à¤· à¤†à¤¦à¤¿ à¤¸à¤®à¤¸à¥à¤¯à¤¾à¤“à¤‚ à¤•à¤¾ à¤¸à¤®à¤¾à¤§à¤¾à¤¨ à¤¤à¥à¤°à¤¨à¥à¤¤ à¤˜à¤° à¤¬à¥ˆà¤ à¥‡ #pt.vk. sharma ji+91-8955545742ðŸ•‰ï¸ 24 hours available..â€¦ðŸ•‰ï¸\"', 'abhy_viness', 'Inteha ho gai', 'havaldar_yadav38', 'Dolan aandolan karte hai', 'thezaheenhussain', '4 days to go.!!!', 'thatcozyvibe', 'kb aa rhi hai mirzapur 2ðŸ˜', '_.nmn07', 'Kab he wo dinðŸ™„\\U0001f97a', 'awadkar19', 'Jaldi', 'one_wise_lyf', 'Kab aayega', 'kilton_sharma', 'waiting for mirzapur 2ðŸ˜ðŸ˜ðŸ˜', 'su.raj__ray', 'ðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜', 'imwasim08', 'Jldi laao yaar ab 2 sal ho gye bc', 'anushreemardi', 'Release kab hoga??? Date???', 'kamil_shayar', 'Ofter 2 week announce the release date thxxx @harshita1210', 'sudhansu.tripathy.5', 'ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸ–¤ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹ðŸŒ¹', 'mdmech.er', 'Abhibhi dubbing chal rahi hai Matlab aur 1 saal to aramse jayega', 'mdmech.er', 'Tub tak to interest bhi mar jata hai', 'miss_lazy_boness', 'Yayyyyyyyyyyyy â¤ï¸â¤ï¸', 'hanif_aliza', 'Chalo kuch toh acha horaha hai 2020 mai ðŸ˜', 'skumarpal277', '@primevideoin bhosadi walon Mirzapur ko gaad me bhar lihiyo ka dalon us ko', 'brutus9907utt', 'ðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜¢â¤ï¸', 'rohit_aggarwal011', 'Waiting for this since last season cameâ¤ï¸â¤ï¸â¤ï¸', 'a.j_jr_4', 'â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸', 'rohit_aggarwal011', 'Just eagerly waiting to watch it n I know everyone just love itðŸ”¥ðŸ”¥', 'akshay_shetty21', 'Aisa bol bolke 2 saal nikal gaye.. jhute sapne mat dikhao madam ðŸ¤—', 'v_anshkumar', 'Nice jee', 'manishasingh2018s', 'Soo beautiful sayukta aap ka gana hame bhi sunna hai piz ðŸ’—ðŸ’—ðŸ’—', 'sipunkumar.88', 'ðŸ™ŒðŸ˜â¤ï¸ mirzapur 2', 'nitishk043', 'bhai jldi release krwa do nai to jis hisaab se 2020 chl ra h.. dunia kbi b khtm ho skti h.ðŸ˜‚', 'riishu_pandit', 'welcome', 'bijon.01', 'â¤ï¸â¤ï¸ðŸ˜', 'aship_lib', 'â¤ï¸â¤ï¸â¤ï¸', 'youth.square', 'ðŸ˜ðŸ˜', 'fabulous_ms7', \"Yeee...!!! ðŸ‘ðŸ˜ƒ That's great!! I'm eagerly waiting for Mirzapur part 2 and in the first part of Mirzapur is really awesome and I hope this one will more interesting and amazing one. All the best mamðŸ‘. And I can't control the happiness that when it gonna release but yes we have to wait or be patience for it but... ðŸ¤žðŸ˜‹â˜ºï¸!! Love you mamðŸ’™ðŸ’š and take care ðŸ¤—\", 'shubham_lede12', 'Kab aayenge woh din', 'tridibesh_das', 'Koi date bata do pls', 'deepthi_immanni', 'Stay safe!!â¤ï¸', 'advsatishdubey', 'Welcome backðŸ‘ŒðŸ‘ŒðŸ‘ŒðŸ‘ŒðŸ‘Œ', '___nodramaplz___', 'Didi please Jaldi Release karwao yrrr aur kitna Intzaar kare @harshita1210', 'devraaz17', 'Jldi laao yrrr....Bahut wait kr rha huðŸ˜­ðŸ˜­ðŸ˜­â¤', 'harsudz1807', '@harshitagaur1210 mam jaldi release date announce kariye.... 2 saal hone ko arha season 1 ko aye...', 'crazyfanofsandhirmansi', \"Can't waittt ðŸ˜ðŸ˜\", 'prasunmannainsta', '@harshita1210 date batao plzzzz plzzz', 'swathi.1709', 'ðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜', 'rigved_girkar', 'Release date nhi jaana ab bas jaldi laadoðŸ”¥ðŸ”¥', 'mr_xkartik', 'Kash wo din kal ho', 'abhijeetb0803', 'Love You Beautiful ðŸ’‹ðŸ’‹ðŸ’‹ðŸ’‹ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸', 'abhi_kangude', 'usi din ka to intezaar hai...', 'mayank_r_0812', 'boht zaida wait hu gya', '_nitin_singla02', 'That smileðŸ˜â¤ï¸', 'jotu_prabhakar', 'Yeaah yeaahhhhðŸ˜ðŸ˜â¤ï¸â¤ï¸â¤ï¸', 'ta_ishq', 'Plsss release it soon!!!', 'bhatt4653', 'When will have mirjapur 2 ?????', 'priyadudwa164_official', 'Please please please please please please please please diiiiiiiiiiii reply me iam your big fan after seeing sadda haq plzz ðŸ™ please diiðŸ˜˜ðŸ˜ðŸ˜˜', 'priyadudwa164_official', 'Love you diiiâ™¥ï¸', 'sauravkumar6261', 'ðŸ‘ŒðŸ‘Œ', 'priyadudwa164_official', 'Love you so much much muchâ¤ï¸ðŸ˜˜ðŸ˜', 'harshita_mysunshine', \"Finally ðŸ¤— #DimpyPandit is here ðŸ’– can't wait to see you back onscreen ðŸ˜­\", 'harshita_mysunshine', 'Please take care of yourself â£ï¸ stay safe ðŸ™', 'shahid_fatima_', 'Wah jeeðŸ‘', 'vedannttttttt', 'Ek hint toh de dijiye release date ka?', 'briantennyson4', 'To iske liye tum hamare gate pe chle aye', 'the_real_owais_khan', 'Dimpy PANDIT pta ny kaahe lkn aapko apne devar ki maut ka dukh ny hai...ðŸ˜‚ðŸ˜‚ By the way u nailed ur partsâ™¥ï¸â™¥ï¸', 'n.i.t.i.n.s.h.a.r.m.a', 'inbox mein date bta do ðŸ˜…ðŸ˜…', 'safwanansarie', 'Approximately?ðŸ˜¬', '_nitin_singla02', 'Aakhir aa hi gyi aapki bari bhiâ¤ï¸', 'vaibhav_yendole', 'Kya badhiya baat sunayi wahhhðŸ˜ðŸ¼', 'bunny_subhash', 'â¤ï¸â¤ï¸', 'bunny_subhash', 'ðŸ˜˜ðŸ˜˜', '__paras__01_', 'ðŸ˜ðŸ˜ðŸ˜', 'urimrannn', 'ðŸ‘', 'urimrannn', 'ðŸ‘Œ', 'urimrannn', 'ðŸ”¥']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jjS9ywz2t8dV","executionInfo":{"status":"ok","timestamp":1601498003427,"user_tz":-330,"elapsed":1488,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"a3224122-014a-4119-debc-1aa3889e57d2","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["df = pd.DataFrame()\n","df[\"documents\"] = sentences\n","df.head()\n","df['clean_documents'] = df['documents'].str.replace(\"[^a-zA-Z#]\", \" \")\n","df['clean_documents'] = df['clean_documents'].fillna('').apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n","df['clean_documents'] = df['clean_documents'].fillna('').apply(lambda x: x.lower())\n","\n","df.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>documents</th>\n","      <th>clean_documents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>user name</td>\n","      <td>user name</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>comments</td>\n","      <td>comments</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madhura_makeupnhair</td>\n","      <td>madhura makeupnhair</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Canâ€™t wait for season 2!!!</td>\n","      <td>can wait for season</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>\"battatawada</td>\n","      <td>battatawada</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    documents      clean_documents\n","0                   user name            user name\n","1                    comments             comments\n","2         madhura_makeupnhair  madhura makeupnhair\n","3  Canâ€™t wait for season 2!!!  can wait for season\n","4                \"battatawada          battatawada"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"cZ9-0Sh1uF5Z"},"source":["# tokenization\n","tokenized_doc = df['clean_documents'].fillna('').apply(lambda x: x.split())\n","\n","# remove stop-words\n","\n","tokenized_doc = tokenized_doc.apply(lambda x: [itemstop_words = stopwords.words('english')\n"," for item in x if item not in stop_words])\n","\n","# de-tokenization\n","detokenized_doc = []\n","for i in range(len(df)):\n","    t = ' '.join(tokenized_doc[i])\n","    detokenized_doc.append(t)\n","\n","df['clean_documents'] = detokenized_doc\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCWTs1BGu6iZ","executionInfo":{"status":"ok","timestamp":1601498234563,"user_tz":-330,"elapsed":1434,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"e69e0d72-e11f-4fe0-9f58-7f868b5d085a","colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["# TF-IDF vector\n","vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n","X = vectorizer.fit_transform(df['clean_documents'])\n","X.toarray()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Krre1Xi0vDTV","executionInfo":{"status":"ok","timestamp":1601498287607,"user_tz":-330,"elapsed":1285,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"833a3a9f-5eea-45b1-e359-e99eaed224db","colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["# SVD represent documents and terms in vectors \n","svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100, random_state=122)\n","lsa = svd_model.fit_transform(X)\n","\n","#Documents - Topic vector\n","pd.options.display.float_format = '{:,.16f}'.format\n","topic_encoded_df = pd.DataFrame(lsa, columns = [\"topic_1\", \"topic_2\"])\n","topic_encoded_df[\"documents\"] = df['clean_documents']\n","display(topic_encoded_df[[\"documents\", \"topic_1\", \"topic_2\"]])"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>documents</th>\n","      <th>topic_1</th>\n","      <th>topic_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>user name</td>\n","      <td>-0.0000000000000000</td>\n","      <td>-0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>comments</td>\n","      <td>0.0000000000000000</td>\n","      <td>0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>madhura makeupnhair</td>\n","      <td>-0.0000000000000000</td>\n","      <td>-0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>can wait for season</td>\n","      <td>-0.0000000000000009</td>\n","      <td>0.0300069253896707</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>battatawada</td>\n","      <td>0.0000000000000000</td>\n","      <td>0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>268</th>\n","      <td></td>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>269</th>\n","      <td>urimrannn</td>\n","      <td>0.0000000000000000</td>\n","      <td>-0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>270</th>\n","      <td></td>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>urimrannn</td>\n","      <td>0.0000000000000000</td>\n","      <td>-0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>272</th>\n","      <td></td>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0000000000000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>273 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["               documents             topic_1             topic_2\n","0              user name -0.0000000000000000 -0.0000000000000000\n","1               comments  0.0000000000000000  0.0000000000000000\n","2    madhura makeupnhair -0.0000000000000000 -0.0000000000000000\n","3    can wait for season -0.0000000000000009  0.0300069253896707\n","4            battatawada  0.0000000000000000  0.0000000000000000\n","..                   ...                 ...                 ...\n","268                      -0.0000000000000000  0.0000000000000000\n","269            urimrannn  0.0000000000000000 -0.0000000000000000\n","270                      -0.0000000000000000  0.0000000000000000\n","271            urimrannn  0.0000000000000000 -0.0000000000000000\n","272                      -0.0000000000000000  0.0000000000000000\n","\n","[273 rows x 3 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"e2F9fFuqvKJN","executionInfo":{"status":"ok","timestamp":1601498320142,"user_tz":-330,"elapsed":1239,"user":{"displayName":"Muskaan Balwani","photoUrl":"","userId":"03272924802870714003"}},"outputId":"5753ae85-2b13-4df8-cf44-fc3f4bf0369a","colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["dictionary = vectorizer.get_feature_names()\n","\n","encoding_matrix = pd.DataFrame(svd_model.components_, index = [\"topic_1\",\"topic_2\"], columns = (dictionary)).T\n","encoding_matrix"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_1</th>\n","      <th>topic_2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>aakhir</th>\n","      <td>-0.0000000000000002</td>\n","      <td>0.0019049074196449</td>\n","    </tr>\n","    <tr>\n","      <th>aandolan</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0008784362662326</td>\n","    </tr>\n","    <tr>\n","      <th>aap</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0014066164190548</td>\n","    </tr>\n","    <tr>\n","      <th>aapki</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0019049074196449</td>\n","    </tr>\n","    <tr>\n","      <th>aapko</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0002411070089272</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>youth</th>\n","      <td>-0.0000000000000000</td>\n","      <td>-0.0000000000000000</td>\n","    </tr>\n","    <tr>\n","      <th>yrr</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0012063529114341</td>\n","    </tr>\n","    <tr>\n","      <th>yrrr</th>\n","      <td>-0.0000000000000005</td>\n","      <td>0.0201925598465197</td>\n","    </tr>\n","    <tr>\n","      <th>zaida</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0014416511410439</td>\n","    </tr>\n","    <tr>\n","      <th>zoobearz</th>\n","      <td>-0.0000000000000000</td>\n","      <td>0.0000000000000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>452 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                     topic_1             topic_2\n","aakhir   -0.0000000000000002  0.0019049074196449\n","aandolan -0.0000000000000000  0.0008784362662326\n","aap      -0.0000000000000000  0.0014066164190548\n","aapki    -0.0000000000000000  0.0019049074196449\n","aapko    -0.0000000000000000  0.0002411070089272\n","...                      ...                 ...\n","youth    -0.0000000000000000 -0.0000000000000000\n","yrr      -0.0000000000000000  0.0012063529114341\n","yrrr     -0.0000000000000005  0.0201925598465197\n","zaida    -0.0000000000000000  0.0014416511410439\n","zoobearz -0.0000000000000000  0.0000000000000000\n","\n","[452 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":9}]}]}